{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c3668e9-260c-4c2d-9c70-d7571c7c38aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import struct\n",
    "\n",
    "__version__ = '0.01.00'\n",
    "\n",
    "# Constants\n",
    "GDFNAMELEN = 16                  # Length of the ascii-names\n",
    "GDFID = 94325877                # ID for GDF\n",
    "\n",
    "# Data types\n",
    "t_undef = int('0000', 16)       # Data type not defined\n",
    "t_ascii = int('0001', 16)       # ASCII character\n",
    "t_s32 = int('0002', 16)       # Signed long\n",
    "t_dbl = int('0003', 16)       # Double\n",
    "t_null = int('0010', 16)       # No data\n",
    "t_u8 = int('0020', 16)       # Unsigned char\n",
    "t_s8 = int('0030', 16)       # Signed char\n",
    "t_u16 = int('0040', 16)       # Unsigned short\n",
    "t_s16 = int('0050', 16)       # Signed short\n",
    "t_u32 = int('0060', 16)       # Unsigned long\n",
    "t_u64 = int('0070', 16)       # Unsigned 64bit int\n",
    "t_s64 = int('0080', 16)       # Signed 64bit int\n",
    "t_flt = int('0090', 16)       # Float\n",
    "\n",
    "# Block types\n",
    "t_dir = 256      # Directory entry start\n",
    "t_edir = 512      # Directory entry end\n",
    "t_sval = 1024      # Single valued\n",
    "t_arr = 2048      # Array\n",
    "\n",
    "\n",
    "# Top level gdf readers\n",
    "def gdftomemory(gdf_file):\n",
    "    all = []\n",
    "\n",
    "    def myprocfunc(params, data):\n",
    "        all.append({'p': params, 'd': data})\n",
    "\n",
    "    print(readgdf(gdf_file, myprocfunc))\n",
    "    return all\n",
    "\n",
    "\n",
    "def gdftopandas(gdf_file):\n",
    "    params = []\n",
    "    data = []\n",
    "    paramid = 1\n",
    "\n",
    "    def myprocfunc(blockparams, blockdata):\n",
    "        nonlocal paramid\n",
    "\n",
    "        temp = blockparams.copy()\n",
    "        temp['paramid'] = paramid\n",
    "        params.append(temp)\n",
    "\n",
    "        temp = blockdata.copy()\n",
    "        try:\n",
    "            templen = len(next(iter(temp.values())))\n",
    "            tempcol = np.full((templen, ), paramid)\n",
    "            temp['paramid'] = tempcol\n",
    "        except StopIteration:\n",
    "            pass\n",
    "        data.append(temp)\n",
    "\n",
    "        paramid += 1\n",
    "\n",
    "    header = readgdf(gdf_file, myprocfunc)\n",
    "\n",
    "    params = pd.DataFrame(params)\n",
    "    params.set_index('paramid', inplace=True)\n",
    "\n",
    "    data = pd.concat([pd.DataFrame(blockdata) for blockdata in data],\n",
    "                     sort=False)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return header, params, data\n",
    "\n",
    "\n",
    "# Internal functions\n",
    "def _parseblocks(f, params, procfunc):\n",
    "    data = {}\n",
    "    while True:\n",
    "        # TODO check end of file?\n",
    "        # Read block header\n",
    "        name = f.read(GDFNAMELEN)\n",
    "        if len(name) == 0:\n",
    "            procfunc(params, data)\n",
    "            return\n",
    "        name = name.decode().rstrip('\\x00')\n",
    "        type_, = struct.unpack('i', f.read(4))\n",
    "        size, = struct.unpack('i', f.read(4))\n",
    "\n",
    "        # Get block type and data type\n",
    "        is_dir = (type_ & t_dir != 0)\n",
    "        is_edir = (type_ & t_edir != 0)\n",
    "        is_sval = (type_ & t_sval != 0)\n",
    "        is_arr = (type_ & t_arr != 0)\n",
    "\n",
    "        dattype = type_ & 255\n",
    "\n",
    "        # Get block data (scalar or array)\n",
    "        if is_sval:\n",
    "            if dattype == t_dbl:\n",
    "                value = struct.unpack('d', f.read(8))[0]\n",
    "            elif dattype == t_null:\n",
    "                pass\n",
    "            elif dattype == t_ascii:\n",
    "                value = f.read(size).decode().rstrip('\\x00')\n",
    "            elif dattype == t_s32:\n",
    "                value = struct.unpack('i', f.read(4))[0]\n",
    "            else:\n",
    "                print('unknown datatype of value!!!')\n",
    "                print('name=', name)\n",
    "                print('type=', type_)\n",
    "                print('size=', size)\n",
    "                print('dattype=', dattype)\n",
    "                value = f.read(size)\n",
    "        elif is_arr:\n",
    "            if dattype == t_dbl:\n",
    "                value = np.frombuffer(f.read(size))\n",
    "                data[name] = value\n",
    "            else:\n",
    "                print('unknown datatype of value!!!')\n",
    "                print('name=', name)\n",
    "                print('type=', type_)\n",
    "                print('size=', size)\n",
    "                print('dattype=', dattype)\n",
    "                value = f.read(size)\n",
    "\n",
    "        # Take care of recursion\n",
    "        if is_dir:\n",
    "            myparams = params.copy()\n",
    "            myparams[name] = value\n",
    "            _parseblocks(f, myparams, procfunc)\n",
    "        elif is_edir:\n",
    "            procfunc(params, data)\n",
    "            return\n",
    "        elif is_sval:\n",
    "            params[name] = value\n",
    "\n",
    "\n",
    "def _proc_print(params, data):\n",
    "    print(params)\n",
    "    print(data.keys())\n",
    "    print('_____________________')\n",
    "\n",
    "\n",
    "# Base gdf reader\n",
    "def readgdf(gdf_file, procfunc=_proc_print):\n",
    "    # Output data\n",
    "    gdf_head = {}\n",
    "\n",
    "    with open(gdf_file, 'rb') as f:\n",
    "        # Read the GDF main header\n",
    "        gdf_id_check = struct.unpack('i', f.read(4))[0]\n",
    "        if gdf_id_check != GDFID:\n",
    "            raise RuntimeWarning('File is not a .gdf file')\n",
    "\n",
    "        time_created = struct.unpack('i', f.read(4))[0]\n",
    "        time_created = datetime.fromtimestamp(time_created)\n",
    "        gdf_head['time_created'] = time_created.isoformat(' ')\n",
    "\n",
    "        gdf_head['creator'] = f.read(GDFNAMELEN).decode().rstrip('\\x00')\n",
    "\n",
    "        gdf_head['destination'] = f.read(GDFNAMELEN).decode().rstrip('\\x00')\n",
    "\n",
    "        major = struct.unpack('B', f.read(1))[0]\n",
    "        minor = struct.unpack('B', f.read(1))[0]\n",
    "        gdf_head['gdf_version'] = str(major) + '.' + str(minor)\n",
    "\n",
    "        major = struct.unpack('B', f.read(1))[0]\n",
    "        minor = struct.unpack('B', f.read(1))[0]\n",
    "        gdf_head['creator_version'] = str(major) + '.' + str(minor)\n",
    "\n",
    "        major = struct.unpack('B', f.read(1))[0]\n",
    "        minor = struct.unpack('B', f.read(1))[0]\n",
    "        gdf_head['destination_version'] = str(major) + '.' + str(minor)\n",
    "\n",
    "        f.seek(2, 1)   # skip 2 bytes to go to next block\n",
    "\n",
    "        # Read GDF data blocks (starts recursive reading)\n",
    "        _parseblocks(f, {}, procfunc)\n",
    "\n",
    "    return gdf_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aae07212-8738-48e8-95c6-b4f868a9b231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time_created': '2024-08-05 13:04:40', 'creator': 'MR', 'destination': '', 'gdf_version': '1.1', 'creator_version': '1.3', 'destination_version': '0.0'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import MaxNLocator, ScalarFormatter\n",
    "\n",
    "\n",
    "data = gdftomemory(\"test.gdf\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_data(timestep, component):\n",
    "    timestep_data = data[timestep].get(\"d\")\n",
    "    x = np.array(timestep_data.get(\"x\"))\n",
    "    y = np.array(timestep_data.get(\"y\"))\n",
    "    z = np.array(timestep_data.get(\"z\"))\n",
    "    q = np.array(timestep_data.get(\"q\"))\n",
    "    var = np.array(timestep_data.get(component))\n",
    "    return x, y, z, q, var\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_zoom_limits(x, y, z, zoom):\n",
    "    x_range, y_range, z_range = x.max() - x.min(), y.max() - y.min(), z.max() - z.min()\n",
    "    zoom_factor = (100 - zoom) / 100\n",
    "    x_center, y_center, z_center = np.mean(x), np.mean(y), np.mean(z)\n",
    "    x_lim = (x_center - x_range * zoom_factor / 2, x_center + x_range * zoom_factor / 2)\n",
    "    y_lim = (y_center - y_range * zoom_factor / 2, y_center + y_range * zoom_factor / 2)\n",
    "    z_lim = (z_center - z_range * zoom_factor / 2, z_center + z_range * zoom_factor / 2)\n",
    "    return x_lim, y_lim, z_lim\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def filter_data(x, y, z, q, var, x_lim, y_lim, z_lim):\n",
    "    mask = (x >= x_lim[0]) & (x <= x_lim[1]) & (y >= y_lim[0]) & (y <= y_lim[1]) & (z >= z_lim[0]) & (z <= z_lim[1])\n",
    "    return x[mask], y[mask], z[mask], q[mask], var[mask]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_3d_scatter(ax, x, y, z, var, component, elevation, rotation, dummy, q):\n",
    "    dummy_mask = q != 0\n",
    "    if dummy:\n",
    "        sc = ax.scatter(z, x, y, c=var, cmap='viridis', s=20, vmin=var.min(), vmax=var.max(), label=component)\n",
    "    else:\n",
    "        sc = ax.scatter(z[dummy_mask], x[dummy_mask], y[dummy_mask], c=var[dummy_mask], cmap='viridis', s=20, vmin=var[dummy_mask].min(), vmax=var[dummy_mask].max(), label=component)\n",
    "    ax.view_init(elev=elevation, azim=rotation + 305)\n",
    "    return sc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_2d_slice(ax, x_slice, y_slice, var_slice, component, var, dummy, q_slice):\n",
    "    dummy_slice_mask = q_slice != 0\n",
    "    if dummy:\n",
    "        sc = ax.scatter(x_slice, y_slice, c=var_slice, cmap='viridis', s=20, vmin=var.min(), vmax=var.max(), label=component)\n",
    "    else:\n",
    "        sc = ax.scatter(x_slice[dummy_slice_mask], y_slice[dummy_slice_mask], c=var_slice[dummy_slice_mask], cmap='viridis', s=20, vmin=var.min(), vmax=var.max(), label=component)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    return sc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_original(timestep=0, component='q', zoom=60, slice_position=50, elevation=30, rotation=0, dummy=True):\n",
    "    x, y, z, q, var = get_data(timestep, component)\n",
    "    x_lim, y_lim, z_lim = calculate_zoom_limits(x, y, z, zoom)\n",
    "    x_filtered, y_filtered, z_filtered, q_filtered, var_filtered = filter_data(x, y, z, q, var, x_lim, y_lim, z_lim)\n",
    "    \n",
    "    fig = plt.figure(figsize=(30, 13))\n",
    "\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    sc1 = plot_3d_scatter(ax1, x_filtered, y_filtered, z_filtered, var_filtered, component, elevation, rotation, dummy, q_filtered)\n",
    "    fig.colorbar(sc1, ax=ax1, label=component)\n",
    "    ax1.set_xlim(z_lim)\n",
    "    ax1.set_ylim(x_lim)\n",
    "    ax1.set_zlim(y_lim)\n",
    "\n",
    "    slice_z_value = z.min() + (slice_position / 100) * (z.max() - z.min())\n",
    "    z_std = np.std(z_filtered)\n",
    "    margin = max(0.03 * (z.max() - z.min()), z_std)\n",
    "    slice_mask = (z_filtered > slice_z_value - margin) & (z_filtered < slice_z_value + margin)\n",
    "    x_slice_zoomed, y_slice_zoomed, var_slice_zoomed, q_slice_zoomed = x_filtered[slice_mask], y_filtered[slice_mask], var_filtered[slice_mask], q_filtered[slice_mask]\n",
    "\n",
    "    if x_slice_zoomed.size > 0 and y_slice_zoomed.size > 0 and var_slice_zoomed.size > 0:\n",
    "        ax2 = fig.add_subplot(122)\n",
    "        sc2 = plot_2d_slice(ax2, x_slice_zoomed, y_slice_zoomed, var_slice_zoomed, component, var_filtered, dummy, q_slice_zoomed)\n",
    "        fig.colorbar(sc2, ax=ax2, label=component)\n",
    "        ax2.set_title(f'Slice at z = {slice_z_value}')\n",
    "    else:\n",
    "        print(\"No data points found in the specified slice range.\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9e35571-62f6-4861-aa50-e5863af576d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c751f9defb54c55851f1833076993e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Component', index=2, options=('fBx', 'fBy', 'fBz', 'fEx', 'fEy', 'fEz', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c19633e114f45afa35a82947da09830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create the sliders\n",
    "component_dropdown = widgets.Dropdown(options=['fBx', 'fBy', 'fBz', 'fEx', 'fEy', 'fEz', 'q'], value='fBz', description='Component')\n",
    "timestep_slider = widgets.IntSlider(min=0, max=len(data)-2, step=1, value=0, description='Timestep')\n",
    "zoom_slider = widgets.IntSlider(min=0, max=98, step=2, value=60, description='Zoom')\n",
    "slice_position_slider = widgets.IntSlider(min=0, max=100, step=1, value=50, description='Slice Position')\n",
    "elevation_slider = widgets.IntSlider(min=0, max=90, step=3, value=30, description='Elevation')\n",
    "rotation_slider = widgets.IntSlider(min=0, max=360, step=5, value=0, description='Rotation')\n",
    "dummy_checkbox = widgets.Checkbox(value=True, description='Dummy')\n",
    "\n",
    "# Function to reset sliders\n",
    "def reset_sliders(*args):\n",
    "    timestep_slider.value = 0\n",
    "    zoom_slider.value = 60\n",
    "    slice_position_slider.value = 50\n",
    "    component_dropdown.value = 'fBz'\n",
    "    elevation_slider.value = 30\n",
    "    rotation_slider.value = 0\n",
    "    dummy_checkbox.value = True\n",
    "\n",
    "# Create a reset button\n",
    "reset_button = widgets.Button(description='Reset')\n",
    "reset_button.on_click(reset_sliders)\n",
    "\n",
    "# Create a VBox layout with all the widgets\n",
    "ui = widgets.VBox([component_dropdown, timestep_slider, zoom_slider, slice_position_slider, elevation_slider, rotation_slider, dummy_checkbox, reset_button])\n",
    "\n",
    "# Link the sliders to the plot function\n",
    "out = widgets.interactive_output(plot_original, {\n",
    "    'timestep': timestep_slider,\n",
    "    'component': component_dropdown,\n",
    "    'zoom': zoom_slider,\n",
    "    'slice_position': slice_position_slider,\n",
    "    'elevation': elevation_slider,\n",
    "    'rotation': rotation_slider,\n",
    "    'dummy': dummy_checkbox\n",
    "})\n",
    "\n",
    "# Display the widgets and output\n",
    "display(ui, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a6911f02-070d-41d8-ada6-ca6e561579f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time_created': '2024-08-05 13:04:40', 'creator': 'MR', 'destination': '', 'gdf_version': '1.1', 'creator_version': '1.3', 'destination_version': '0.0'}\n",
      "0.005088994708282135\n",
      "-103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1384563/246587972.py:15: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  V1 = np.float(np.std(data[i].get(\"d\").get('y')[mask]))\n"
     ]
    }
   ],
   "source": [
    "data = gdftomemory(\"test.gdf\")\n",
    "\n",
    "#print(data[1])\n",
    "\n",
    "max = float(0)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(data) - 1):\n",
    "    \n",
    "    q = data[i].get(\"d\").get('q')\n",
    "\n",
    "    mask = q != 0\n",
    "    \n",
    "    V1 = np.float(np.std(data[i].get(\"d\").get('y')[mask]))\n",
    "    if V1 > max:\n",
    "        max = V1\n",
    "        \n",
    "\n",
    "print(max)\n",
    "# print(np.std(data[0].get(\"d\").get('y')))\n",
    "# print(np.std(data[0].get(\"d\").get('z')))\n",
    "\n",
    "\n",
    "print(np.count_nonzero(data[i].get(\"d\").get('fEx')) - len(data[i].get(\"d\").get('fEx')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818552e7-820f-480c-8fea-f292d6f613eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
