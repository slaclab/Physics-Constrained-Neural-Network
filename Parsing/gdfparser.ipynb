{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c3668e9-260c-4c2d-9c70-d7571c7c38aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import struct\n",
    "\n",
    "__version__ = '0.01.00'\n",
    "\n",
    "# Constants\n",
    "GDFNAMELEN = 16                  # Length of the ascii-names\n",
    "GDFID = 94325877                # ID for GDF\n",
    "\n",
    "# Data types\n",
    "t_undef = int('0000', 16)       # Data type not defined\n",
    "t_ascii = int('0001', 16)       # ASCII character\n",
    "t_s32 = int('0002', 16)       # Signed long\n",
    "t_dbl = int('0003', 16)       # Double\n",
    "t_null = int('0010', 16)       # No data\n",
    "t_u8 = int('0020', 16)       # Unsigned char\n",
    "t_s8 = int('0030', 16)       # Signed char\n",
    "t_u16 = int('0040', 16)       # Unsigned short\n",
    "t_s16 = int('0050', 16)       # Signed short\n",
    "t_u32 = int('0060', 16)       # Unsigned long\n",
    "t_u64 = int('0070', 16)       # Unsigned 64bit int\n",
    "t_s64 = int('0080', 16)       # Signed 64bit int\n",
    "t_flt = int('0090', 16)       # Float\n",
    "\n",
    "# Block types\n",
    "t_dir = 256      # Directory entry start\n",
    "t_edir = 512      # Directory entry end\n",
    "t_sval = 1024      # Single valued\n",
    "t_arr = 2048      # Array\n",
    "\n",
    "\n",
    "# Top level gdf readers\n",
    "def gdftomemory(gdf_file):\n",
    "    all = []\n",
    "\n",
    "    def myprocfunc(params, data):\n",
    "        all.append({'p': params, 'd': data})\n",
    "\n",
    "    print(readgdf(gdf_file, myprocfunc))\n",
    "    return all\n",
    "\n",
    "\n",
    "def gdftopandas(gdf_file):\n",
    "    params = []\n",
    "    data = []\n",
    "    paramid = 1\n",
    "\n",
    "    def myprocfunc(blockparams, blockdata):\n",
    "        nonlocal paramid\n",
    "\n",
    "        temp = blockparams.copy()\n",
    "        temp['paramid'] = paramid\n",
    "        params.append(temp)\n",
    "\n",
    "        temp = blockdata.copy()\n",
    "        try:\n",
    "            templen = len(next(iter(temp.values())))\n",
    "            tempcol = np.full((templen, ), paramid)\n",
    "            temp['paramid'] = tempcol\n",
    "        except StopIteration:\n",
    "            pass\n",
    "        data.append(temp)\n",
    "\n",
    "        paramid += 1\n",
    "\n",
    "    header = readgdf(gdf_file, myprocfunc)\n",
    "\n",
    "    params = pd.DataFrame(params)\n",
    "    params.set_index('paramid', inplace=True)\n",
    "\n",
    "    data = pd.concat([pd.DataFrame(blockdata) for blockdata in data],\n",
    "                     sort=False)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return header, params, data\n",
    "\n",
    "\n",
    "# Internal functions\n",
    "def _parseblocks(f, params, procfunc):\n",
    "    data = {}\n",
    "    while True:\n",
    "        # TODO check end of file?\n",
    "        # Read block header\n",
    "        name = f.read(GDFNAMELEN)\n",
    "        if len(name) == 0:\n",
    "            procfunc(params, data)\n",
    "            return\n",
    "        name = name.decode().rstrip('\\x00')\n",
    "        type_, = struct.unpack('i', f.read(4))\n",
    "        size, = struct.unpack('i', f.read(4))\n",
    "\n",
    "        # Get block type and data type\n",
    "        is_dir = (type_ & t_dir != 0)\n",
    "        is_edir = (type_ & t_edir != 0)\n",
    "        is_sval = (type_ & t_sval != 0)\n",
    "        is_arr = (type_ & t_arr != 0)\n",
    "\n",
    "        dattype = type_ & 255\n",
    "\n",
    "        # Get block data (scalar or array)\n",
    "        if is_sval:\n",
    "            if dattype == t_dbl:\n",
    "                value = struct.unpack('d', f.read(8))[0]\n",
    "            elif dattype == t_null:\n",
    "                pass\n",
    "            elif dattype == t_ascii:\n",
    "                value = f.read(size).decode().rstrip('\\x00')\n",
    "            elif dattype == t_s32:\n",
    "                value = struct.unpack('i', f.read(4))[0]\n",
    "            else:\n",
    "                print('unknown datatype of value!!!')\n",
    "                print('name=', name)\n",
    "                print('type=', type_)\n",
    "                print('size=', size)\n",
    "                print('dattype=', dattype)\n",
    "                value = f.read(size)\n",
    "        elif is_arr:\n",
    "            if dattype == t_dbl:\n",
    "                value = np.frombuffer(f.read(size))\n",
    "                data[name] = value\n",
    "            else:\n",
    "                print('unknown datatype of value!!!')\n",
    "                print('name=', name)\n",
    "                print('type=', type_)\n",
    "                print('size=', size)\n",
    "                print('dattype=', dattype)\n",
    "                value = f.read(size)\n",
    "\n",
    "        # Take care of recursion\n",
    "        if is_dir:\n",
    "            myparams = params.copy()\n",
    "            myparams[name] = value\n",
    "            _parseblocks(f, myparams, procfunc)\n",
    "        elif is_edir:\n",
    "            procfunc(params, data)\n",
    "            return\n",
    "        elif is_sval:\n",
    "            params[name] = value\n",
    "\n",
    "\n",
    "def _proc_print(params, data):\n",
    "    print(params)\n",
    "    print(data.keys())\n",
    "    print('_____________________')\n",
    "\n",
    "\n",
    "# Base gdf reader\n",
    "def readgdf(gdf_file, procfunc=_proc_print):\n",
    "    # Output data\n",
    "    gdf_head = {}\n",
    "\n",
    "    with open(gdf_file, 'rb') as f:\n",
    "        # Read the GDF main header\n",
    "        gdf_id_check = struct.unpack('i', f.read(4))[0]\n",
    "        if gdf_id_check != GDFID:\n",
    "            raise RuntimeWarning('File is not a .gdf file')\n",
    "\n",
    "        time_created = struct.unpack('i', f.read(4))[0]\n",
    "        time_created = datetime.fromtimestamp(time_created)\n",
    "        gdf_head['time_created'] = time_created.isoformat(' ')\n",
    "\n",
    "        gdf_head['creator'] = f.read(GDFNAMELEN).decode().rstrip('\\x00')\n",
    "\n",
    "        gdf_head['destination'] = f.read(GDFNAMELEN).decode().rstrip('\\x00')\n",
    "\n",
    "        major = struct.unpack('B', f.read(1))[0]\n",
    "        minor = struct.unpack('B', f.read(1))[0]\n",
    "        gdf_head['gdf_version'] = str(major) + '.' + str(minor)\n",
    "\n",
    "        major = struct.unpack('B', f.read(1))[0]\n",
    "        minor = struct.unpack('B', f.read(1))[0]\n",
    "        gdf_head['creator_version'] = str(major) + '.' + str(minor)\n",
    "\n",
    "        major = struct.unpack('B', f.read(1))[0]\n",
    "        minor = struct.unpack('B', f.read(1))[0]\n",
    "        gdf_head['destination_version'] = str(major) + '.' + str(minor)\n",
    "\n",
    "        f.seek(2, 1)   # skip 2 bytes to go to next block\n",
    "\n",
    "        # Read GDF data blocks (starts recursive reading)\n",
    "        _parseblocks(f, {}, procfunc)\n",
    "\n",
    "    return gdf_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b2733e8-44fe-4bfa-9cd8-68551482e2d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time_created': '2024-07-05 13:46:35', 'creator': 'MR', 'destination': '', 'gdf_version': '1.1', 'creator_version': '1.3', 'destination_version': '0.0'}\n",
      "202\n",
      "xmin:  -0.000524511592356779\n",
      "xmax:  0.0005244785471739739\n",
      "ymin:  -0.0005356632346170567\n",
      "ymax:  0.0005413384044049486\n",
      "z_range:  0.0002685141967746496\n",
      "Fixed bin volume: 1.851548460369426e-14\n",
      "B_max_global: 0.16646476783769779\n",
      "J_max_global: 4.292585313939298\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 5004 into shape (128,128,128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 156\u001b[0m\n\u001b[1;32m    153\u001b[0m By_original \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data[step]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBy\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    154\u001b[0m Bz_original \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data[step]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBz\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 156\u001b[0m original_Bx_data[step] \u001b[38;5;241m=\u001b[39m \u001b[43mBx_original\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_pixels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_pixels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_pixels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m original_By_data[step] \u001b[38;5;241m=\u001b[39m By_original\u001b[38;5;241m.\u001b[39mreshape((n_pixels, n_pixels, n_pixels))\n\u001b[1;32m    158\u001b[0m original_Bz_data[step] \u001b[38;5;241m=\u001b[39m Bz_original\u001b[38;5;241m.\u001b[39mreshape((n_pixels, n_pixels, n_pixels))\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 5004 into shape (128,128,128)"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = '/pscratch/sd/j/jcurcio/pcnn/Volume_Data/'\n",
    "\n",
    "n_pixels = 256\n",
    "c = 2.99792458e8  # Speed of light\n",
    "\n",
    "data = gdftomemory(\"PINN_trainingData_03.gdf\")\n",
    "\n",
    "\n",
    "# Determine max height, max width, and max bunch length across all timesteps\n",
    "z_max_range = 0\n",
    "x_min = float(\"inf\")\n",
    "x_max = float(\"-inf\")\n",
    "y_min = float(\"inf\")\n",
    "y_max = float(\"-inf\")\n",
    "\n",
    "B_max_global = float(\"-inf\")\n",
    "J_max_global = float(\"-inf\")\n",
    "\n",
    "for step in range(len(data) - 1):\n",
    "    x = np.array(data[step].get(\"d\").get(\"x\"))\n",
    "    y = np.array(data[step].get(\"d\").get(\"y\"))\n",
    "    z = np.array(data[step].get(\"d\").get(\"z\"))\n",
    "    q = np.array(data[step].get(\"d\").get(\"q\"))\n",
    "\n",
    "    # Create a mask for the real particles. We don't care about the dummy particles\n",
    "    mask = q != 0\n",
    "    x_real = x[mask]\n",
    "    y_real = y[mask]\n",
    "    z_real = z[mask]\n",
    "\n",
    "    x_min = min(x_min, x_real.min())\n",
    "    x_max = max(x_max, x_real.max())\n",
    "    y_min = min(y_min, y_real.min())\n",
    "    y_max = max(y_max, y_real.max())\n",
    "\n",
    "    z_range = z_real.max() - z_real.min()\n",
    "\n",
    "    if z_range > z_max_range:\n",
    "        z_max_range = z_range\n",
    "\n",
    "xbins = np.linspace(x_min, x_max, n_pixels + 1)\n",
    "ybins = np.linspace(y_min, y_max, n_pixels + 1)\n",
    "\n",
    "bin_volume = z_max_range * (xbins[1] - xbins[0]) * (ybins[1] - ybins[0])\n",
    "\n",
    "print('xmin: ', x_min)\n",
    "print('xmax: ', x_max)\n",
    "print('ymin: ', y_min)\n",
    "print('ymax: ', y_max)\n",
    "print('z_range: ', z_max_range)\n",
    "\n",
    "print(len(data))\n",
    "print(len(data[0].get(\"d\")))\n",
    "print(data[0].get(\"d\"))\n",
    "\n",
    "# Begin calculating and binning data\n",
    "for step in range(len(data)):\n",
    "    # Retrieve data\n",
    "    x = np.array(data[step].get(\"d\").get(\"x\"))\n",
    "    y = np.array(data[step].get(\"d\").get(\"y\"))\n",
    "    z = np.array(data[step].get(\"d\").get(\"z\"))\n",
    "    q = np.array(data[step].get(\"d\").get(\"q\"))\n",
    "\n",
    "    mask = q != 0\n",
    "    z_real = z[mask]\n",
    "    z_min_current = z_real.min()\n",
    "    zbins = np.linspace(z_min_current, z_min_current + z_max_range, n_pixels + 1)\n",
    "\n",
    "    # Retrieve data\n",
    "    components = {\n",
    "        \"Ex\": np.array(data[step].get(\"d\").get(\"fEx\")),\n",
    "        \"Ey\": np.array(data[step].get(\"d\").get(\"fEy\")),\n",
    "        \"Ez\": np.array(data[step].get(\"d\").get(\"fEz\")),\n",
    "        \"Bx\": np.array(data[step].get(\"d\").get(\"fBx\")),  # fBx represents magnetic x\n",
    "        \"By\": np.array(data[step].get(\"d\").get(\"fBy\")),\n",
    "        \"Bz\": np.array(data[step].get(\"d\").get(\"fBz\")),\n",
    "        \"q\": np.array(data[step].get(\"d\").get(\"q\")),\n",
    "    }\n",
    "\n",
    "    velocities = {\n",
    "        \"Bx\": np.array(data[step].get(\"d\").get(\"Bx\")),\n",
    "        \"By\": np.array(data[step].get(\"d\").get(\"By\")),\n",
    "        \"Bz\": np.array(data[step].get(\"d\").get(\"Bz\")),\n",
    "    }\n",
    "\n",
    "    binning_result = {}\n",
    "\n",
    "\n",
    "\n",
    "    # Binning\n",
    "    for key, data_comp in components.items():\n",
    "        if key == 'q':\n",
    "            hist, _ = np.histogramdd((x[mask], y[mask], z[mask]), bins=[xbins, ybins, zbins], weights=data_comp[mask], density=True) # apply q != 0 mask to only bin real particles for rho\n",
    "            binning_result[key] = hist\n",
    "        else:\n",
    "            hist, _ = np.histogramdd((x, y, z), bins=[xbins, ybins, zbins], weights=data_comp) # bin both real and dummy particles for E and B\n",
    "            binning_result[key] = hist\n",
    "\n",
    "    # Save each binned result as a file\n",
    "    for component in components:\n",
    "        binned = binning_result[component]\n",
    "        np.save(OUTPUT_PATH + f'{component}_3D_vol_{n_pixels}_{step}.npy', binned)\n",
    "\n",
    "    # Calculate J components\n",
    "    Jx = components[\"q\"][mask] * velocities[\"Bx\"][mask] * c / bin_volume\n",
    "    Jy = components[\"q\"][mask] * velocities[\"By\"][mask] * c / bin_volume\n",
    "    Jz = components[\"q\"][mask] * velocities[\"Bz\"][mask] * c / bin_volume\n",
    "\n",
    "    j_components = {\n",
    "        \"Jx\": Jx,\n",
    "        \"Jy\": Jy,\n",
    "        \"Jz\": Jz,\n",
    "    }\n",
    "\n",
    "    # Bin J\n",
    "    for j_key, j_data in j_components.items():\n",
    "        hist, _ = np.histogramdd((x[mask], y[mask], z[mask]), bins=[xbins, ybins, zbins], weights=j_data, density=True)\n",
    "        np.save(OUTPUT_PATH + f'{j_key}_3D_vol_{n_pixels}_{step}.npy', hist)\n",
    "\n",
    "\n",
    "    # Find B and J max for normalization\n",
    "    B_max_global = max(B_max_global, components[\"Bx\"][mask].max(), components[\"By\"][mask].max(), components[\"Bz\"][mask].max())\n",
    "    J_max_global = max(J_max_global, Jx.max(), Jy.max(), Jz.max())\n",
    "\n",
    "\n",
    "np.save(OUTPUT_PATH + 'Bxyz_max.npy', B_max_global)\n",
    "np.save(OUTPUT_PATH + 'J_max_max_all_128.npy', J_max_global)\n",
    "\n",
    "print(\"Fixed bin volume:\", bin_volume)\n",
    "print(\"B_max_global:\", B_max_global)\n",
    "print(\"J_max_global:\", J_max_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e7998e69-0fe2-488a-bc44-b0b845f631af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time_created': '2024-07-20 19:06:55', 'creator': 'MR', 'destination': '', 'gdf_version': '1.1', 'creator_version': '1.3', 'destination_version': '0.0'}\n",
      "Saved frame 0 as Bz_timestep_0.png\n",
      "Saved frame 1 as Bz_timestep_1.png\n",
      "Saved frame 2 as Bz_timestep_2.png\n",
      "Saved frame 3 as Bz_timestep_3.png\n",
      "Saved frame 4 as Bz_timestep_4.png\n",
      "Saved frame 5 as Bz_timestep_5.png\n",
      "Saved frame 6 as Bz_timestep_6.png\n",
      "Saved frame 7 as Bz_timestep_7.png\n",
      "Saved frame 8 as Bz_timestep_8.png\n",
      "Saved frame 9 as Bz_timestep_9.png\n",
      "Saved frame 10 as Bz_timestep_10.png\n",
      "Saved frame 11 as Bz_timestep_11.png\n",
      "Saved frame 12 as Bz_timestep_12.png\n",
      "Saved frame 13 as Bz_timestep_13.png\n",
      "Saved frame 14 as Bz_timestep_14.png\n",
      "Saved frame 15 as Bz_timestep_15.png\n",
      "Saved frame 16 as Bz_timestep_16.png\n",
      "Saved frame 17 as Bz_timestep_17.png\n",
      "Saved frame 18 as Bz_timestep_18.png\n",
      "Saved frame 19 as Bz_timestep_19.png\n",
      "Saved frame 20 as Bz_timestep_20.png\n",
      "Saved frame 21 as Bz_timestep_21.png\n",
      "Saved frame 22 as Bz_timestep_22.png\n",
      "Saved frame 23 as Bz_timestep_23.png\n",
      "Saved frame 24 as Bz_timestep_24.png\n",
      "Saved frame 25 as Bz_timestep_25.png\n",
      "Saved frame 26 as Bz_timestep_26.png\n",
      "Saved frame 27 as Bz_timestep_27.png\n",
      "Saved frame 28 as Bz_timestep_28.png\n",
      "Saved frame 29 as Bz_timestep_29.png\n",
      "Saved frame 30 as Bz_timestep_30.png\n",
      "Saved frame 31 as Bz_timestep_31.png\n",
      "Saved frame 32 as Bz_timestep_32.png\n",
      "Saved frame 33 as Bz_timestep_33.png\n",
      "Saved frame 34 as Bz_timestep_34.png\n",
      "Saved frame 35 as Bz_timestep_35.png\n",
      "Saved frame 36 as Bz_timestep_36.png\n",
      "Saved frame 37 as Bz_timestep_37.png\n",
      "Saved frame 38 as Bz_timestep_38.png\n",
      "Saved frame 39 as Bz_timestep_39.png\n",
      "Saved frame 40 as Bz_timestep_40.png\n",
      "Saved frame 41 as Bz_timestep_41.png\n",
      "Saved frame 42 as Bz_timestep_42.png\n",
      "Saved frame 43 as Bz_timestep_43.png\n",
      "Saved frame 44 as Bz_timestep_44.png\n",
      "Saved frame 45 as Bz_timestep_45.png\n",
      "Saved frame 46 as Bz_timestep_46.png\n",
      "Saved frame 47 as Bz_timestep_47.png\n",
      "Saved frame 48 as Bz_timestep_48.png\n",
      "Saved frame 49 as Bz_timestep_49.png\n",
      "Saved frame 50 as Bz_timestep_50.png\n",
      "Saved frame 51 as Bz_timestep_51.png\n",
      "Saved frame 52 as Bz_timestep_52.png\n",
      "Saved frame 53 as Bz_timestep_53.png\n",
      "Saved frame 54 as Bz_timestep_54.png\n",
      "Saved frame 55 as Bz_timestep_55.png\n",
      "Saved frame 56 as Bz_timestep_56.png\n",
      "Saved frame 57 as Bz_timestep_57.png\n",
      "Saved frame 58 as Bz_timestep_58.png\n",
      "Saved frame 59 as Bz_timestep_59.png\n",
      "Saved frame 60 as Bz_timestep_60.png\n",
      "Saved frame 61 as Bz_timestep_61.png\n",
      "Saved frame 62 as Bz_timestep_62.png\n",
      "Saved frame 63 as Bz_timestep_63.png\n",
      "Saved frame 64 as Bz_timestep_64.png\n",
      "Saved frame 65 as Bz_timestep_65.png\n",
      "Saved frame 66 as Bz_timestep_66.png\n",
      "Saved frame 67 as Bz_timestep_67.png\n",
      "Saved frame 68 as Bz_timestep_68.png\n",
      "Saved frame 69 as Bz_timestep_69.png\n",
      "Saved frame 70 as Bz_timestep_70.png\n",
      "Saved frame 71 as Bz_timestep_71.png\n",
      "Saved frame 72 as Bz_timestep_72.png\n",
      "Saved frame 73 as Bz_timestep_73.png\n",
      "Saved frame 74 as Bz_timestep_74.png\n",
      "Saved frame 75 as Bz_timestep_75.png\n",
      "Saved frame 76 as Bz_timestep_76.png\n",
      "Saved frame 77 as Bz_timestep_77.png\n",
      "Saved frame 78 as Bz_timestep_78.png\n",
      "Saved frame 79 as Bz_timestep_79.png\n",
      "Saved frame 80 as Bz_timestep_80.png\n",
      "Saved frame 81 as Bz_timestep_81.png\n",
      "Saved frame 82 as Bz_timestep_82.png\n",
      "Saved frame 83 as Bz_timestep_83.png\n",
      "Saved frame 84 as Bz_timestep_84.png\n",
      "Saved frame 85 as Bz_timestep_85.png\n",
      "Saved frame 86 as Bz_timestep_86.png\n",
      "Saved frame 87 as Bz_timestep_87.png\n",
      "Saved frame 88 as Bz_timestep_88.png\n",
      "Saved frame 89 as Bz_timestep_89.png\n",
      "Saved frame 90 as Bz_timestep_90.png\n",
      "Saved frame 91 as Bz_timestep_91.png\n",
      "Saved frame 92 as Bz_timestep_92.png\n",
      "Saved frame 93 as Bz_timestep_93.png\n",
      "Saved frame 94 as Bz_timestep_94.png\n",
      "Saved frame 95 as Bz_timestep_95.png\n",
      "Saved frame 96 as Bz_timestep_96.png\n",
      "Saved frame 97 as Bz_timestep_97.png\n",
      "Saved frame 98 as Bz_timestep_98.png\n",
      "Saved frame 99 as Bz_timestep_99.png\n",
      "Saved frame 100 as Bz_timestep_100.png\n",
      "Saved frame 101 as Bz_timestep_101.png\n",
      "Saved frame 102 as Bz_timestep_102.png\n",
      "Saved frame 103 as Bz_timestep_103.png\n",
      "Saved frame 104 as Bz_timestep_104.png\n",
      "Saved frame 105 as Bz_timestep_105.png\n",
      "Saved frame 106 as Bz_timestep_106.png\n",
      "Saved frame 107 as Bz_timestep_107.png\n",
      "Saved frame 108 as Bz_timestep_108.png\n",
      "Saved frame 109 as Bz_timestep_109.png\n",
      "Saved frame 110 as Bz_timestep_110.png\n",
      "Saved frame 111 as Bz_timestep_111.png\n",
      "Saved frame 112 as Bz_timestep_112.png\n",
      "Saved frame 113 as Bz_timestep_113.png\n",
      "Saved frame 114 as Bz_timestep_114.png\n",
      "Saved frame 115 as Bz_timestep_115.png\n",
      "Saved frame 116 as Bz_timestep_116.png\n",
      "Saved frame 117 as Bz_timestep_117.png\n",
      "Saved frame 118 as Bz_timestep_118.png\n",
      "Saved frame 119 as Bz_timestep_119.png\n",
      "Saved frame 120 as Bz_timestep_120.png\n",
      "Saved frame 121 as Bz_timestep_121.png\n",
      "Saved frame 122 as Bz_timestep_122.png\n",
      "Saved frame 123 as Bz_timestep_123.png\n",
      "Saved frame 124 as Bz_timestep_124.png\n",
      "Saved frame 125 as Bz_timestep_125.png\n",
      "Appended Bz_timestep_0.png to GIF\n",
      "Appended Bz_timestep_1.png to GIF\n",
      "Appended Bz_timestep_2.png to GIF\n",
      "Appended Bz_timestep_3.png to GIF\n",
      "Appended Bz_timestep_4.png to GIF\n",
      "Appended Bz_timestep_5.png to GIF\n",
      "Appended Bz_timestep_6.png to GIF\n",
      "Appended Bz_timestep_7.png to GIF\n",
      "Appended Bz_timestep_8.png to GIF\n",
      "Appended Bz_timestep_9.png to GIF\n",
      "Appended Bz_timestep_10.png to GIF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_220912/2291803557.py:111: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended Bz_timestep_11.png to GIF\n",
      "Appended Bz_timestep_12.png to GIF\n",
      "Appended Bz_timestep_13.png to GIF\n",
      "Appended Bz_timestep_14.png to GIF\n",
      "Appended Bz_timestep_15.png to GIF\n",
      "Appended Bz_timestep_16.png to GIF\n",
      "Appended Bz_timestep_17.png to GIF\n",
      "Appended Bz_timestep_18.png to GIF\n",
      "Appended Bz_timestep_19.png to GIF\n",
      "Appended Bz_timestep_20.png to GIF\n",
      "Appended Bz_timestep_21.png to GIF\n",
      "Appended Bz_timestep_22.png to GIF\n",
      "Appended Bz_timestep_23.png to GIF\n",
      "Appended Bz_timestep_24.png to GIF\n",
      "Appended Bz_timestep_25.png to GIF\n",
      "Appended Bz_timestep_26.png to GIF\n",
      "Appended Bz_timestep_27.png to GIF\n",
      "Appended Bz_timestep_28.png to GIF\n",
      "Appended Bz_timestep_29.png to GIF\n",
      "Appended Bz_timestep_30.png to GIF\n",
      "Appended Bz_timestep_31.png to GIF\n",
      "Appended Bz_timestep_32.png to GIF\n",
      "Appended Bz_timestep_33.png to GIF\n",
      "Appended Bz_timestep_34.png to GIF\n",
      "Appended Bz_timestep_35.png to GIF\n",
      "Appended Bz_timestep_36.png to GIF\n",
      "Appended Bz_timestep_37.png to GIF\n",
      "Appended Bz_timestep_38.png to GIF\n",
      "Appended Bz_timestep_39.png to GIF\n",
      "Appended Bz_timestep_40.png to GIF\n",
      "Appended Bz_timestep_41.png to GIF\n",
      "Appended Bz_timestep_42.png to GIF\n",
      "Appended Bz_timestep_43.png to GIF\n",
      "Appended Bz_timestep_44.png to GIF\n",
      "Appended Bz_timestep_45.png to GIF\n",
      "Appended Bz_timestep_46.png to GIF\n",
      "Appended Bz_timestep_47.png to GIF\n",
      "Appended Bz_timestep_48.png to GIF\n",
      "Appended Bz_timestep_49.png to GIF\n",
      "Appended Bz_timestep_50.png to GIF\n",
      "Appended Bz_timestep_51.png to GIF\n",
      "Appended Bz_timestep_52.png to GIF\n",
      "Appended Bz_timestep_53.png to GIF\n",
      "Appended Bz_timestep_54.png to GIF\n",
      "Appended Bz_timestep_55.png to GIF\n",
      "Appended Bz_timestep_56.png to GIF\n",
      "Appended Bz_timestep_57.png to GIF\n",
      "Appended Bz_timestep_58.png to GIF\n",
      "Appended Bz_timestep_59.png to GIF\n",
      "Appended Bz_timestep_60.png to GIF\n",
      "Appended Bz_timestep_61.png to GIF\n",
      "Appended Bz_timestep_62.png to GIF\n",
      "Appended Bz_timestep_63.png to GIF\n",
      "Appended Bz_timestep_64.png to GIF\n",
      "Appended Bz_timestep_65.png to GIF\n",
      "Appended Bz_timestep_66.png to GIF\n",
      "Appended Bz_timestep_67.png to GIF\n",
      "Appended Bz_timestep_68.png to GIF\n",
      "Appended Bz_timestep_69.png to GIF\n",
      "Appended Bz_timestep_70.png to GIF\n",
      "Appended Bz_timestep_71.png to GIF\n",
      "Appended Bz_timestep_72.png to GIF\n",
      "Appended Bz_timestep_73.png to GIF\n",
      "Appended Bz_timestep_74.png to GIF\n",
      "Appended Bz_timestep_75.png to GIF\n",
      "Appended Bz_timestep_76.png to GIF\n",
      "Appended Bz_timestep_77.png to GIF\n",
      "Appended Bz_timestep_78.png to GIF\n",
      "Appended Bz_timestep_79.png to GIF\n",
      "Appended Bz_timestep_80.png to GIF\n",
      "Appended Bz_timestep_81.png to GIF\n",
      "Appended Bz_timestep_82.png to GIF\n",
      "Appended Bz_timestep_83.png to GIF\n",
      "Appended Bz_timestep_84.png to GIF\n",
      "Appended Bz_timestep_85.png to GIF\n",
      "Appended Bz_timestep_86.png to GIF\n",
      "Appended Bz_timestep_87.png to GIF\n",
      "Appended Bz_timestep_88.png to GIF\n",
      "Appended Bz_timestep_89.png to GIF\n",
      "Appended Bz_timestep_90.png to GIF\n",
      "Appended Bz_timestep_91.png to GIF\n",
      "Appended Bz_timestep_92.png to GIF\n",
      "Appended Bz_timestep_93.png to GIF\n",
      "Appended Bz_timestep_94.png to GIF\n",
      "Appended Bz_timestep_95.png to GIF\n",
      "Appended Bz_timestep_96.png to GIF\n",
      "Appended Bz_timestep_97.png to GIF\n",
      "Appended Bz_timestep_98.png to GIF\n",
      "Appended Bz_timestep_99.png to GIF\n",
      "Appended Bz_timestep_100.png to GIF\n",
      "Appended Bz_timestep_101.png to GIF\n",
      "Appended Bz_timestep_102.png to GIF\n",
      "Appended Bz_timestep_103.png to GIF\n",
      "Appended Bz_timestep_104.png to GIF\n",
      "Appended Bz_timestep_105.png to GIF\n",
      "Appended Bz_timestep_106.png to GIF\n",
      "Appended Bz_timestep_107.png to GIF\n",
      "Appended Bz_timestep_108.png to GIF\n",
      "Appended Bz_timestep_109.png to GIF\n",
      "Appended Bz_timestep_110.png to GIF\n",
      "Appended Bz_timestep_111.png to GIF\n",
      "Appended Bz_timestep_112.png to GIF\n",
      "Appended Bz_timestep_113.png to GIF\n",
      "Appended Bz_timestep_114.png to GIF\n",
      "Appended Bz_timestep_115.png to GIF\n",
      "Appended Bz_timestep_116.png to GIF\n",
      "Appended Bz_timestep_117.png to GIF\n",
      "Appended Bz_timestep_118.png to GIF\n",
      "Appended Bz_timestep_119.png to GIF\n",
      "Appended Bz_timestep_120.png to GIF\n",
      "Appended Bz_timestep_121.png to GIF\n",
      "Appended Bz_timestep_122.png to GIF\n",
      "Appended Bz_timestep_123.png to GIF\n",
      "Appended Bz_timestep_124.png to GIF\n",
      "Appended Bz_timestep_125.png to GIF\n",
      "GIF saved as Bz_output.gif\n",
      "Removed 126 temporary PNG files.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import imageio\n",
    "import os\n",
    "from matplotlib.ticker import MaxNLocator, ScalarFormatter\n",
    "\n",
    "OUTPUT_PATH = '/pscratch/sd/j/jcurcio/pcnn/Volume_Data/'\n",
    "\n",
    "data = gdftomemory(\"PINN_trainingData_03.gdf\")\n",
    "\n",
    "# Assuming n_pixels is defined somewhere in your script\n",
    "n_pixels = 128\n",
    "\n",
    "# Assuming global min and max values are known for x and y\n",
    "global_x_min = -0.000524511592356779\n",
    "global_x_max = 0.0005244785471739739\n",
    "global_y_min = -0.0005356632346170567\n",
    "global_y_max = 0.0005413384044049486\n",
    "\n",
    "def plot_variable(variable_name, data_length, xbins, ybins, data):\n",
    "    filenames = []  # List to store filenames for deletion\n",
    "\n",
    "    # Calculate the centers of the bins for x and y\n",
    "    x_centers = 0.5 * (xbins[:-1] + xbins[1:])\n",
    "    y_centers = 0.5 * (ybins[:-1] + ybins[1:])\n",
    "\n",
    "    for i in range(data_length):\n",
    "        fig = plt.figure(figsize=(10, 8))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        # Load binned data from npy file for the chosen variable\n",
    "        file_path = OUTPUT_PATH + f'{variable_name}_3D_vol_{n_pixels}_{i}.npy'\n",
    "\n",
    "        # Check if the file exists to handle any missing files\n",
    "        if not os.path.exists(file_path):\n",
    "            binned_data = np.zeros((n_pixels, n_pixels, n_pixels))\n",
    "            print(f\"File not found, creating an all-zero placeholder for: {file_path}\")\n",
    "        else:\n",
    "            binned_data = np.load(file_path)\n",
    "\n",
    "        # Check if the binned data contains only zeros\n",
    "        if np.all(binned_data == 0):\n",
    "            print(f\"File contains only zeros: {file_path}\")\n",
    "\n",
    "        # Retrieve the actual z data for the current timestep\n",
    "        z_data = data[i].get(\"d\").get(\"z\")\n",
    "        z = np.array(z_data)\n",
    "        z_min_current = z.min()\n",
    "        z_max_current = z.max()\n",
    "\n",
    "        # Calculate the centers of the z bins for the current timestep\n",
    "        zbins = np.linspace(z_min_current, z_max_current, n_pixels + 1)\n",
    "        z_centers = 0.5 * (zbins[:-1] + zbins[1:])\n",
    "\n",
    "        # Create meshgrid for plotting\n",
    "        X, Y, Z = np.meshgrid(x_centers, y_centers, z_centers, indexing='ij')\n",
    "\n",
    "        # Flatten arrays for plotting\n",
    "        x_flattened = X.flatten()\n",
    "        y_flattened = Y.flatten()\n",
    "        z_flattened = Z.flatten()\n",
    "\n",
    "        # Get non-zero indices for the chosen variable\n",
    "        non_zero_indices = np.nonzero(binned_data.flatten())\n",
    "\n",
    "        # Scatter plot of non-zero binned data points for the chosen variable\n",
    "        if len(non_zero_indices[0]) > 0:\n",
    "            sc = ax.scatter(z_flattened[non_zero_indices], x_flattened[non_zero_indices],\n",
    "                            y_flattened[non_zero_indices], c=binned_data.flatten()[non_zero_indices],\n",
    "                            cmap='viridis', s=50, vmin=binned_data.min(), vmax=binned_data.max())\n",
    "            fig.colorbar(sc, label=variable_name)\n",
    "        else:\n",
    "            # Add a placeholder plot for all-zero data\n",
    "            ax.text2D(0.5, 0.5, \"No Data\", horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
    "\n",
    "        # Set consistent axis limits for x and y\n",
    "        ax.set_xlim(z_min_current, z_max_current)\n",
    "        ax.set_ylim(global_x_min, global_x_max)\n",
    "        ax.set_zlim(global_y_min, global_y_max)\n",
    "\n",
    "        # Customize plot appearance\n",
    "        ax.set_xlabel('Z')\n",
    "        ax.set_ylabel('X')\n",
    "        ax.set_zlabel('Y')\n",
    "        ax.set_title(f'Binned 3D Scatter Plot of {variable_name} - Timestep {i}')\n",
    "\n",
    "        # Adjust viewing angle\n",
    "        ax.view_init(elev=30, azim=-60)\n",
    "\n",
    "        # Format the tick labels to reduce precision\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(nbins=5))\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(nbins=5))\n",
    "        ax.zaxis.set_major_locator(MaxNLocator(nbins=5))\n",
    "\n",
    "        ax.xaxis.set_major_formatter(ScalarFormatter(useOffset=False, useMathText=True))\n",
    "        ax.yaxis.set_major_formatter(ScalarFormatter(useOffset=False, useMathText=True))\n",
    "        ax.zaxis.set_major_formatter(ScalarFormatter(useOffset=False, useMathText=True))\n",
    "\n",
    "        # Save each plot as a PNG file\n",
    "        filename = f'{variable_name}_timestep_{i}.png'\n",
    "        plt.savefig(filename)\n",
    "        plt.close(fig)  # Close the figure to release resources\n",
    "        filenames.append(filename)\n",
    "        print(f\"Saved frame {i} as {filename}\")\n",
    "\n",
    "    # Generate the GIF from the saved PNG files\n",
    "    gif_filename = f'{variable_name}_output.gif'\n",
    "    with imageio.get_writer(gif_filename, mode='I', duration=0.1, loop=0) as writer:  # Set duration to 0.1 seconds per frame\n",
    "        for filename in filenames:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "            print(f\"Appended {filename} to GIF\")\n",
    "\n",
    "    print(f'GIF saved as {gif_filename}')\n",
    "\n",
    "    # Remove the image files after creating the GIF\n",
    "    for filename in filenames:\n",
    "        os.remove(filename)\n",
    "\n",
    "    print(f'Removed {len(filenames)} temporary PNG files.')\n",
    "\n",
    "# Assuming 'data' is already defined and contains 200 timesteps\n",
    "data_length = len(data) - 1\n",
    "\n",
    "# Assuming xbins and ybins are defined\n",
    "xbins = np.linspace(global_x_min, global_x_max, n_pixels + 1)\n",
    "ybins = np.linspace(global_y_min, global_y_max, n_pixels + 1)\n",
    "\n",
    "plot_variable('Bz', data_length, xbins, ybins, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "aae07212-8738-48e8-95c6-b4f868a9b231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time_created': '2024-07-20 19:06:55', 'creator': 'MR', 'destination': '', 'gdf_version': '1.1', 'creator_version': '1.3', 'destination_version': '0.0'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import MaxNLocator, ScalarFormatter\n",
    "\n",
    "\n",
    "data = gdftomemory(\"PINN_trainingData_03.gdf\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_data(timestep, component):\n",
    "    timestep_data = data[timestep].get(\"d\")\n",
    "    x = np.array(timestep_data.get(\"x\"))\n",
    "    y = np.array(timestep_data.get(\"y\"))\n",
    "    z = np.array(timestep_data.get(\"z\"))\n",
    "    q = np.array(timestep_data.get(\"q\"))\n",
    "    var = np.array(timestep_data.get(component))\n",
    "    return x, y, z, q, var\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_zoom_limits(x, y, z, zoom):\n",
    "    x_range, y_range, z_range = x.max() - x.min(), y.max() - y.min(), z.max() - z.min()\n",
    "    zoom_factor = (100 - zoom) / 100\n",
    "    x_center, y_center, z_center = np.mean(x), np.mean(y), np.mean(z)\n",
    "    x_lim = (x_center - x_range * zoom_factor / 2, x_center + x_range * zoom_factor / 2)\n",
    "    y_lim = (y_center - y_range * zoom_factor / 2, y_center + y_range * zoom_factor / 2)\n",
    "    z_lim = (z_center - z_range * zoom_factor / 2, z_center + z_range * zoom_factor / 2)\n",
    "    return x_lim, y_lim, z_lim\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def filter_data(x, y, z, q, var, x_lim, y_lim, z_lim):\n",
    "    mask = (x >= x_lim[0]) & (x <= x_lim[1]) & (y >= y_lim[0]) & (y <= y_lim[1]) & (z >= z_lim[0]) & (z <= z_lim[1])\n",
    "    return x[mask], y[mask], z[mask], q[mask], var[mask]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_3d_scatter(ax, x, y, z, var, component, elevation, rotation, dummy, q):\n",
    "    dummy_mask = q != 0\n",
    "    if dummy:\n",
    "        sc = ax.scatter(z, x, y, c=var, cmap='viridis', s=20, vmin=var.min(), vmax=var.max(), label=component)\n",
    "    else:\n",
    "        sc = ax.scatter(z[dummy_mask], x[dummy_mask], y[dummy_mask], c=var[dummy_mask], cmap='viridis', s=20, vmin=var[dummy_mask].min(), vmax=var[dummy_mask].max(), label=component)\n",
    "    ax.view_init(elev=elevation, azim=rotation + 305)\n",
    "    return sc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_2d_slice(ax, x_slice, y_slice, var_slice, component, var, dummy, q_slice):\n",
    "    dummy_slice_mask = q_slice != 0\n",
    "    if dummy:\n",
    "        sc = ax.scatter(x_slice, y_slice, c=var_slice, cmap='viridis', s=20, vmin=var.min(), vmax=var.max(), label=component)\n",
    "    else:\n",
    "        sc = ax.scatter(x_slice[dummy_slice_mask], y_slice[dummy_slice_mask], c=var_slice[dummy_slice_mask], cmap='viridis', s=20, vmin=var.min(), vmax=var.max(), label=component)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    return sc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_original(timestep=0, component='q', zoom=60, slice_position=50, elevation=30, rotation=0, dummy=True):\n",
    "    x, y, z, q, var = get_data(timestep, component)\n",
    "    x_lim, y_lim, z_lim = calculate_zoom_limits(x, y, z, zoom)\n",
    "    x_filtered, y_filtered, z_filtered, q_filtered, var_filtered = filter_data(x, y, z, q, var, x_lim, y_lim, z_lim)\n",
    "    \n",
    "    fig = plt.figure(figsize=(30, 13))\n",
    "\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    sc1 = plot_3d_scatter(ax1, x_filtered, y_filtered, z_filtered, var_filtered, component, elevation, rotation, dummy, q_filtered)\n",
    "    fig.colorbar(sc1, ax=ax1, label=component)\n",
    "    ax1.set_xlim(z_lim)\n",
    "    ax1.set_ylim(x_lim)\n",
    "    ax1.set_zlim(y_lim)\n",
    "\n",
    "    slice_z_value = z.min() + (slice_position / 100) * (z.max() - z.min())\n",
    "    z_std = np.std(z_filtered)\n",
    "    margin = max(0.03 * (z.max() - z.min()), z_std)\n",
    "    slice_mask = (z_filtered > slice_z_value - margin) & (z_filtered < slice_z_value + margin)\n",
    "    x_slice_zoomed, y_slice_zoomed, var_slice_zoomed, q_slice_zoomed = x_filtered[slice_mask], y_filtered[slice_mask], var_filtered[slice_mask], q_filtered[slice_mask]\n",
    "\n",
    "    if x_slice_zoomed.size > 0 and y_slice_zoomed.size > 0 and var_slice_zoomed.size > 0:\n",
    "        ax2 = fig.add_subplot(122)\n",
    "        sc2 = plot_2d_slice(ax2, x_slice_zoomed, y_slice_zoomed, var_slice_zoomed, component, var_filtered, dummy, q_slice_zoomed)\n",
    "        fig.colorbar(sc2, ax=ax2, label=component)\n",
    "        ax2.set_title(f'Slice at z = {slice_z_value}')\n",
    "    else:\n",
    "        print(\"No data points found in the specified slice range.\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e9e35571-62f6-4861-aa50-e5863af576d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1602d6737ca64944b6118608517858bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Component', index=2, options=('fBx', 'fBy', 'fBz', 'fEx', 'fEy', 'fEz', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817db3c722e74905928913fbbb401db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create the sliders\n",
    "component_dropdown = widgets.Dropdown(options=['fBx', 'fBy', 'fBz', 'fEx', 'fEy', 'fEz', 'q'], value='fBz', description='Component')\n",
    "timestep_slider = widgets.IntSlider(min=0, max=len(data)-2, step=1, value=0, description='Timestep')\n",
    "zoom_slider = widgets.IntSlider(min=0, max=98, step=2, value=60, description='Zoom')\n",
    "slice_position_slider = widgets.IntSlider(min=0, max=100, step=1, value=50, description='Slice Position')\n",
    "elevation_slider = widgets.IntSlider(min=0, max=90, step=3, value=30, description='Elevation')\n",
    "rotation_slider = widgets.IntSlider(min=0, max=360, step=5, value=0, description='Rotation')\n",
    "dummy_checkbox = widgets.Checkbox(value=True, description='Dummy')\n",
    "\n",
    "# Function to reset sliders\n",
    "def reset_sliders(*args):\n",
    "    timestep_slider.value = 0\n",
    "    zoom_slider.value = 60\n",
    "    slice_position_slider.value = 50\n",
    "    component_dropdown.value = 'fBz'\n",
    "    elevation_slider.value = 30\n",
    "    rotation_slider.value = 0\n",
    "    dummy_checkbox.value = True\n",
    "\n",
    "# Create a reset button\n",
    "reset_button = widgets.Button(description='Reset')\n",
    "reset_button.on_click(reset_sliders)\n",
    "\n",
    "# Create a VBox layout with all the widgets\n",
    "ui = widgets.VBox([component_dropdown, timestep_slider, zoom_slider, slice_position_slider, elevation_slider, rotation_slider, dummy_checkbox, reset_button])\n",
    "\n",
    "# Link the sliders to the plot function\n",
    "out = widgets.interactive_output(plot_original, {\n",
    "    'timestep': timestep_slider,\n",
    "    'component': component_dropdown,\n",
    "    'zoom': zoom_slider,\n",
    "    'slice_position': slice_position_slider,\n",
    "    'elevation': elevation_slider,\n",
    "    'rotation': rotation_slider,\n",
    "    'dummy': dummy_checkbox\n",
    "})\n",
    "\n",
    "# Display the widgets and output\n",
    "display(ui, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "816dba7f-9ecc-46f0-83e4-5c1f40d20ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea751e56dd94d5da25ed480d62b80a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='timestep', max=125), Dropdown(description='component', i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_original(timestep=0, component='q', zoom=60, slice_position=50, elevation=30, rotation=0, dummy=True)>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipywidgets.interact(plot_original, timestep=(0,len(data)-2,1), zoom=(0,98,2), slice_position=(0,100,1), component=['fBx', 'fBy', 'fBz', 'fEx', 'fEy', 'fEz', 'q', ], elevation=(0,90,3), rotation=(0,360,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb00ed80-f3c9-4f9e-81a5-642efa0d88dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7b2192ce-9e0d-4d39-8f34-0c22ddd4dd78",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PINN_trainingData_02.gdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save original data for prediction comparison purposes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m OUTPUT_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/pscratch/sd/j/jcurcio/pcnn/Volume_Data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mgdftomemory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPINN_trainingData_02.gdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      6\u001b[0m original_Bx_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data[step]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfBx\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[4], line 41\u001b[0m, in \u001b[0;36mgdftomemory\u001b[0;34m(gdf_file)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmyprocfunc\u001b[39m(params, data):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mall\u001b[39m\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m: params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m: data})\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mreadgdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgdf_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmyprocfunc\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m\n",
      "Cell \u001b[0;32mIn[4], line 154\u001b[0m, in \u001b[0;36mreadgdf\u001b[0;34m(gdf_file, procfunc)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadgdf\u001b[39m(gdf_file, procfunc\u001b[38;5;241m=\u001b[39m_proc_print):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# Output data\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     gdf_head \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgdf_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;66;03m# Read the GDF main header\u001b[39;00m\n\u001b[1;32m    156\u001b[0m         gdf_id_check \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m, f\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gdf_id_check \u001b[38;5;241m!=\u001b[39m GDFID:\n",
      "File \u001b[0;32m/global/common/software/nersc9/tensorflow/2.9.0/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PINN_trainingData_02.gdf'"
     ]
    }
   ],
   "source": [
    "# Save original data for prediction comparison purposes\n",
    "OUTPUT_PATH = '/pscratch/sd/j/jcurcio/pcnn/Volume_Data/'\n",
    "data = gdftomemory(\"PINN_trainingData_02.gdf\")\n",
    "step = 10\n",
    "\n",
    "original_Bx_data = np.array(data[step].get(\"d\").get(\"fBx\"))\n",
    "original_By_data = np.array(data[step].get(\"d\").get(\"fBy\"))\n",
    "original_Bz_data = np.array(data[step].get(\"d\").get(\"fBz\"))\n",
    "\n",
    "# Save the original Bx, By, and Bz data\n",
    "np.save(OUTPUT_PATH + 'original_Bx_data.npy', original_Bx_data)\n",
    "np.save(OUTPUT_PATH + 'original_By_data.npy', original_By_data)\n",
    "np.save(OUTPUT_PATH + 'original_Bz_data.npy', original_Bz_data)\n",
    "\n",
    "print(\"Original Bx, By, and Bz data saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72328e4-f819-4219-9af6-a0ddead99670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
